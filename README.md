# 2D ‚Üí 3D Video Converter (MiDaS)

A simple Python tool that converts **normal 2D videos** into **immersive 3D** using **MiDaS depth estimation**.  
It supports **Red/Cyan Anaglyph** (red‚Äìcyan glasses) and **Side‚Äëby‚ÄëSide** (SBS) stereo output.  
Optional **CUDA acceleration**, **mixed precision** (faster on NVIDIA GPUs), and **FFmpeg pre‚Äëencoding** are built‚Äëin for smooth, high‚Äëquality results.

> **Author:** Ayan Khan  
> **Current script:** `2D to 3D Photo and Video.py` (v2.9.2025‚Äë1)

---

## ‚ú® Highlights

- **Depth from single frames** with MiDaS models (DPT_Large / DPT_Hybrid / MiDaS_small)
- **Two 3D formats**: Red/Cyan Anaglyph and Side‚Äëby‚ÄëSide (SBS)
- **CUDA + AMP** (automatic mixed precision) for speed on NVIDIA
- **FFmpeg pre‚Äëencode** option for reliable decoding of tricky source files
- **Safe depth normalization** to avoid NaNs/Infs and crashes
- **Progress prints** every 50 frames and a final saved path

---

## üì¶ Requirements

- **Python** 3.9+ (3.10/3.11 recommended)
- **Pip packages:**
  - `torch` (CPU or CUDA build)
  - `opencv-python`
  - `numpy`
- **FFmpeg** (optional, but recommended for the pre‚Äëencode step)

> ‚ö†Ô∏è For NVIDIA GPUs, install a **CUDA-enabled** build of PyTorch that matches your driver/CUDA version.  
> See the official PyTorch site for the correct `pip` command for your system.

### Install dependencies

```bash
# Create/activate a virtual env (recommended)
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

# Core deps
pip install --upgrade pip
pip install torch opencv-python numpy
# If you have an NVIDIA GPU, install the CUDA build of torch per pytorch.org
```

### FFmpeg (optional but useful)

- **Windows:** Install FFmpeg and add it to PATH.  
- **Linux/macOS:** Install via your package manager or official builds.  

The tool will still work without FFmpeg, but **pre‚Äëencoding** can fix many decode issues and make processing smoother.

---

## üì• Models (MiDaS)

The app loads MiDaS models directly via **`torch.hub`** from `intel-isl/MiDaS`. On first run, it will **download** the model weights to your Torch cache:

- `DPT_Large` ‚Üí `dpt_large_384.pt` (highest quality, slowest)  
- `DPT_Hybrid` ‚Üí `dpt_hybrid_384.pt` (quality/speed balance)  
- `MiDaS_small` ‚Üí `midas_v21_small_256.pt` (fastest, lower quality)

You can also **provide your own model file** (for offline use). The tool will copy it into `~/.cache/torch/hub/checkpoints/` with the expected filename.

---

## ‚ñ∂Ô∏è Usage (Interactive CLI)

Run the script (quote the filename since it has spaces):

```bash
python "2D to 3D Photo and Video.py"
```

You will be asked a few simple questions:

1) **Choose model**  
   `1. DPT_Large` ¬∑ `2. DPT_Hybrid` ¬∑ `3. MiDaS_small`

2) **Model source**  
   `1. Already Downloaded` (give path to your local .pt file)  
   `2. Download Automatically / Use Cached` (recommended)

3) **Use CUDA?**  
   `1. Yes` (if you have an NVIDIA GPU + CUDA PyTorch)  
   `2. No (CPU)`

4) **Enable mixed precision (AMP)?** *(only shown when CUDA is on)*  
   `1. Yes` (faster on modern GPUs) ¬∑ `2. No`

5) **Input video path**  
   Paste or drag‚Äëdrop the full path to your source video file.

6) **Pre‚Äëencode with FFmpeg?**  
   `1. Yes` ‚Üí re‚Äëencodes to H.264/AAC for reliable decoding  
   `2. No` ‚Üí use original video as is

7) **Choose output format**  
   `1. Red/Cyan Anaglyph` (works with cheap red‚Äëcyan glasses)  
   `2. SBS Stereo` (two views side‚Äëby‚Äëside; good for VR players/TVs)

8) **Max shift (pixels)**  
   Horizontal pixel shift based on depth map. Default is **15**.  
   Larger values = stronger 3D effect, but too large can look uncomfortable.

The app will print progress every 50 frames and save the output video next to your input:

- **Anaglyph:** `output_anaglyph_video-<n>.mp4`  
- **SBS:** `output_sbs_video-<n>.mp4`

---

## üß† How it works (plain English)

- For each frame, MiDaS predicts a **depth map** (which parts are near/far).  
- We **normalize** that depth safely and create a **shift map**.  
- We **warp** the original frame left/right using that shift to make **two views** (left eye, right eye).  
- For **Anaglyph**, we mix channels (Left ‚Üí Red, Right ‚Üí Green+Blue).  
- For **SBS**, we place the two views **side-by-side**.

This is a **2D‚Äëto‚Äë3D approximation**. It won‚Äôt be perfect like true stereo capture, but with the right settings it looks surprisingly good.

---

## ‚öôÔ∏è Options & Tips

- **Model choice:**  
  - *Best quality:* `DPT_Large`  
  - *Balanced:* `DPT_Hybrid`  
  - *Fastest:* `MiDaS_small`
- **Max shift:** Start with **15**. Try 8‚Äì24 depending on content and comfort.
- **FFmpeg pre‚Äëencode:** If your video fails to open or stutters, choose **Yes**.
- **AMP (mixed precision):** Usually faster on RTX GPUs. If you see artifacts or errors, turn it **off**.
- **Frame rate & size:** Output uses the source **FPS** and **resolution**.  
  SBS doubles width (W ‚Üí **2W**), height stays the same.

---

## üß™ Example

```bash
python "2D to 3D Photo and Video.py"
# Choose: 2 (DPT_Hybrid)
# Source: 2 (Auto/Cache)
# CUDA: 1 (Yes)  ‚Üí AMP: 1 (Yes)
# Input: C:\Videos\clip.mp4
# Pre-encode: 1 (Yes)
# Output: 2 (SBS Stereo)
# Max shift: 16
# ‚Üí Saved: output_sbs_video-1.mp4
```

---

## üõ† Troubleshooting

- **‚ÄúFailed to open video.‚Äù**  
  Use the **FFmpeg pre‚Äëencode** option. If it still fails, ensure FFmpeg is installed and that the path has **no special characters**.

- **Very slow / Out of memory (GPU).**  
  Use **MiDaS_small**, disable **AMP**, or switch to **CPU**. Close other GPU-heavy apps.

- **Weird color/ghosting in Anaglyph.**  
  This is normal if the 3D shift is too strong. **Lower Max shift** or try **SBS**.

- **Depth looks inverted (near/far flipped).**  
  Try smaller **Max shift**. If the scene still feels wrong, you can try inverting the direction (edit code: swap `map_x_left` and `map_x_right` lines).

- **Artifacts at edges.**  
  The script uses **border replication** to avoid holes. Minor stretching at frame borders is expected.

---

## üìö Project Structure

- `2D to 3D Photo and Video.py` ‚Üí main interactive script  
  - MiDaS load via `torch.hub`  
  - Safe depth normalization  
  - Optional **FFmpeg** re‚Äëencode  
  - **Anaglyph** and **SBS** writers

You can rename the script if you like, just keep the code intact.

---

## üó∫ Roadmap (ideas)

- CLI flags (non‚Äëinteractive mode)  
- Per‚Äëscene **depth smoothing** / temporal consistency  
- Adjustable **parallax curve** (non‚Äëlinear shift by depth)  
- **Green/Magenta** anaglyph and other stereo layouts  
- **Batch processing** of folders

---

## ü§ù Contributing

PRs and issues are welcome. Please describe your system, Python version, and exact steps to reproduce any bug.

---

## üìú License

Choose the license you prefer (MIT, Apache‚Äë2.0, etc.) and add a `LICENSE` file.  
If unsure, MIT is a good simple choice.

---

## üôè Credits

- **MiDaS** by Intel ISL (loaded via `torch.hub`)  
- Thanks to the open‚Äësource community for PyTorch, OpenCV, NumPy, and FFmpeg.

